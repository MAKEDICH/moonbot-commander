"""
–°–æ–±—ã—Ç–∏—è –∑–∞–ø—É—Å–∫–∞ –∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

Startup –∏ shutdown handlers –¥–ª—è FastAPI.
–û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é UDP listeners, scheduler –∏ graceful shutdown.

–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –≤—ã—Å–æ–∫–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫ (3000+ —Å–µ—Ä–≤–µ—Ä–æ–≤):
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis –∫—ç—à–∞
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –ë–î
- Batch processor –¥–ª—è UDP —Å–æ–æ–±—â–µ–Ω–∏–π
"""
import asyncio
import traceback
from datetime import datetime
from typing import TYPE_CHECKING, List, Optional, Dict, Any

from models.database import SessionLocal
from models import models
from services import udp, encryption
from services import scheduler as scheduler_module
from services.websocket_manager import ws_manager
from services.update_checker import check_update_on_startup
from utils.logging import log, check_and_manage_all_logs
from utils.config_loader import get_config_value

if TYPE_CHECKING:
    from fastapi import FastAPI


async def _init_high_load_components() -> None:
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è –≤—ã—Å–æ–∫–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫.
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –í–û –í–°–ï–• –†–ï–ñ–ò–ú–ê–•
    (local, server, dev, production).
    
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç:
    - Worker Pool –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ UDP
    - Batch Processor –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∑–∞–ø–∏—Å–µ–π –≤ –ë–î
    - Redis –∫—ç—à (—Å fallback –Ω–∞ in-memory)
    - –ò–Ω–¥–µ–∫—Å—ã –ë–î –¥–ª—è –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    import os
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
    moonbot_mode = os.getenv('MOONBOT_MODE', 'auto').lower()
    log(f"[STARTUP] ============================================================")
    log(f"[STARTUP] üöÄ HIGH-LOAD MODE: Enabled for ALL modes (local/server/dev/prod)")
    log(f"[STARTUP] üìã MOONBOT_MODE: {moonbot_mode}")
    log(f"[STARTUP] ============================================================")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Worker Pool –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ UDP
    try:
        from services.udp.worker_pool import start_worker_pool, get_worker_pool
        start_worker_pool()
        pool = get_worker_pool()
        log(f"[STARTUP] ‚úÖ UDP Worker Pool started ({pool.num_workers} workers, "
            f"queue_size={pool.queue_size})")
    except Exception as e:
        log(f"[STARTUP] Worker Pool init failed: {e}", level="WARNING")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Batch Processor –¥–ª—è UDP —Å–æ–æ–±—â–µ–Ω–∏–π
    try:
        from services.udp.batch_processor import start_batch_processor, get_batch_processor
        start_batch_processor()
        processor = get_batch_processor()
        log(f"[STARTUP] ‚úÖ Batch Processor started (batch_size={processor.batch_size}, "
            f"flush_interval={processor.flush_interval_ms}ms)")
    except Exception as e:
        log(f"[STARTUP] Batch Processor init failed: {e}", level="WARNING")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis –∫—ç—à–∞ (—Å fallback –Ω–∞ in-memory)
    try:
        from services.redis_cache import get_redis_cache
        cache = await get_redis_cache()
        stats = await cache.get_stats()
        if stats.get("using_fallback"):
            log("[STARTUP] ‚ö†Ô∏è Redis not available, using in-memory cache (OK for dev)")
        else:
            log("[STARTUP] ‚úÖ Redis cache connected")
    except Exception as e:
        log(f"[STARTUP] Redis init skipped: {e}", level="DEBUG")
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –≤—ã—Å–æ–∫–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫ (–µ—Å–ª–∏ –µ—â—ë –Ω–µ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã)
    try:
        from updates.versions.add_high_load_indexes import check_migration_needed, run_migration
        if check_migration_needed():
            log("[STARTUP] Applying high-load database indexes...")
            run_migration()
            log("[STARTUP] ‚úÖ High-load indexes applied")
        else:
            log("[STARTUP] ‚úÖ High-load indexes already applied")
    except Exception as e:
        log(f"[STARTUP] High-load indexes skipped: {e}", level="DEBUG")
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–ª—è cleanup_settings (–Ω–æ–≤—ã–µ –ø–æ–ª—è –¥–ª—è 3000+ —Å–µ—Ä–≤–µ—Ä–æ–≤)
    try:
        from updates.versions.add_cleanup_settings_columns import (
            check_migration_needed as check_cleanup_migration,
            run_migration as run_cleanup_migration
        )
        if check_cleanup_migration():
            log("[STARTUP] Applying cleanup settings migration...")
            run_cleanup_migration()
            log("[STARTUP] ‚úÖ Cleanup settings migration applied")
        else:
            log("[STARTUP] ‚úÖ Cleanup settings already up to date")
    except Exception as e:
        log(f"[STARTUP] Cleanup settings migration skipped: {e}", level="DEBUG")
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è ForeignKey –ø–æ–ª–µ–π
    try:
        from updates.versions.add_missing_indexes import (
            check_migration_needed as check_indexes_migration,
            run_migration as run_indexes_migration
        )
        if check_indexes_migration():
            log("[STARTUP] Applying missing indexes migration...")
            run_indexes_migration()
            log("[STARTUP] ‚úÖ Missing indexes applied")
        else:
            log("[STARTUP] ‚úÖ All indexes already exist")
    except Exception as e:
        log(f"[STARTUP] Missing indexes migration skipped: {e}", level="DEBUG")
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–ª—è scheduled_command_servers (group_name)
    try:
        from updates.versions.add_scheduled_command_servers_group_name import (
            check_migration_needed as check_scs_migration,
            run_migration as run_scs_migration
        )
        if check_scs_migration():
            log("[STARTUP] Applying scheduled_command_servers migration...")
            run_scs_migration()
            log("[STARTUP] ‚úÖ scheduled_command_servers migration applied")
        else:
            log("[STARTUP] ‚úÖ scheduled_command_servers already up to date")
    except Exception as e:
        log(f"[STARTUP] scheduled_command_servers migration skipped: {e}", level="DEBUG")
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è nullable server_id
    try:
        from updates.versions.fix_scheduled_command_servers_nullable import (
            check_migration_needed as check_nullable_migration,
            run_migration as run_nullable_migration
        )
        if check_nullable_migration():
            log("[STARTUP] Applying fix_scheduled_command_servers_nullable migration...")
            run_nullable_migration()
            log("[STARTUP] ‚úÖ fix_scheduled_command_servers_nullable migration applied")
        else:
            log("[STARTUP] ‚úÖ scheduled_command_servers.server_id already nullable")
    except Exception as e:
        log(f"[STARTUP] fix_scheduled_command_servers_nullable migration skipped: {e}", level="DEBUG")
    
    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—ç—à–∞ user_id –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
    try:
        from services.user_id_cache import populate_cache_from_db
        count = populate_cache_from_db()
        log(f"[STARTUP] ‚úÖ User ID cache populated ({count} servers)")
    except Exception as e:
        log(f"[STARTUP] User ID cache init failed: {e}", level="WARNING")


async def startup_handler() -> None:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
    
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
    - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –≤—ã—Å–æ–∫–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫
    - –ó–∞–ø—É—Å–∫–∞–µ—Ç UDP listeners –¥–ª—è –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
    - –ó–∞–ø—É—Å–∫–∞–µ—Ç scheduler
    """
    log("[STARTUP] Initializing...")
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º event loop –¥–ª—è WebSocket manager
    loop: asyncio.AbstractEventLoop = asyncio.get_event_loop()
    ws_manager.set_event_loop(loop)
    log("[STARTUP] WebSocket manager event loop configured")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è –≤—ã—Å–æ–∫–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫
    await _init_high_load_components()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    log("[STARTUP] Checking for updates...")
    try:
        update_notification: Optional[Dict[str, Any]] = await check_update_on_startup()
        if update_notification:
            log(
                f"[STARTUP] üÜï Update available: "
                f"v{update_notification['current_version']} ‚Üí v{update_notification['new_version']}"
            )
            ws_manager.update_notification = update_notification
    except Exception as e:
        log(f"[STARTUP] Update check failed: {e}", level="WARNING")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è UDP Listeners
    log("[STARTUP] Initializing UDP Listeners...")
    db = SessionLocal()
    try:
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Ä–≤–µ—Ä–æ–≤ (–Ω–µ –≤—Å–µ, —á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å –ø—Ä–∏ 3000+)
        all_servers: List[models.Server] = db.query(models.Server).all()
        log(f"[STARTUP] Total servers in DB: {len(all_servers)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        if len(all_servers) <= 10:
            for s in all_servers:
                log(f"  - Server ID={s.id}, Name={s.name}, Active={s.is_active}, User={s.user_id}")
        else:
            log(f"[STARTUP] (showing first 10 of {len(all_servers)})")
            for s in all_servers[:10]:
                log(f"  - Server ID={s.id}, Name={s.name}, Active={s.is_active}, User={s.user_id}")
        
        servers: List[models.Server] = db.query(models.Server).filter(
            models.Server.is_active == True
        ).all()

        log(f"[STARTUP] Found {len(servers)} active servers")
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è 3000+ —Å–µ—Ä–≤–µ—Ä–æ–≤: –∑–∞–ø—É—Å–∫–∞–µ–º listeners –ø–∞–∫–µ—Ç–∞–º–∏
        # —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å —Å–∏—Å—Ç–µ–º—É
        BATCH_SIZE = 100
        started_count = 0
        failed_count = 0
        
        for i in range(0, len(servers), BATCH_SIZE):
            batch = servers[i:i + BATCH_SIZE]
            batch_num = i // BATCH_SIZE + 1
            total_batches = (len(servers) + BATCH_SIZE - 1) // BATCH_SIZE
            
            log(f"[STARTUP] Starting listeners batch {batch_num}/{total_batches} ({len(batch)} servers)...")
            
            for server in batch:
                try:
                    password: Optional[str] = None
                    if server.password:
                        password = encryption.decrypt_password(server.password)

                    success: bool = udp.start_listener(
                        server_id=server.id,
                        host=server.host,
                        port=server.port,
                        password=password,
                        keepalive_enabled=server.keepalive_enabled
                    )

                    if success:
                        started_count += 1
                    else:
                        failed_count += 1
                        log(
                            f"[STARTUP] ‚ùå Failed to start listener for server {server.id}: {server.name}",
                            level="ERROR"
                        )

                except Exception as e:
                    failed_count += 1
                    log(f"[STARTUP] ‚ùå Error starting listener for server {server.id}: {e}", level="ERROR")
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            if i + BATCH_SIZE < len(servers):
                await asyncio.sleep(0.1)
        
        log(f"[STARTUP] ‚úÖ Listeners started: {started_count} OK, {failed_count} failed")

    except Exception as e:
        log(f"[STARTUP] Error during startup: {e}", level="ERROR")
        log(f"[STARTUP] Traceback: {traceback.format_exc()}", level="DEBUG")
    finally:
        db.close()

    log("[STARTUP] UDP Listeners initialization complete")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ listeners
    asyncio.create_task(monitor_listeners())
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º scheduler –∫–∞–∫ —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
    log("[STARTUP] Starting Command Scheduler...")
    asyncio.create_task(run_scheduler())
    log("[STARTUP] Command Scheduler started")


async def monitor_listeners() -> None:
    """
    –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ —É–ø–∞–≤—à–∏—Ö listeners.
    
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ listeners –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ—Ç
    —É–ø–∞–≤—à–∏–µ –¥–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤.
    """
    while True:
        await asyncio.sleep(60)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É

        try:
            db = SessionLocal()
            try:
                servers: List[models.Server] = db.query(models.Server).filter(
                    models.Server.is_active == True
                ).all()

                for server in servers:
                    listener_status: Dict[str, Any] = udp.get_listener_status(server.id)

                    # –ï—Å–ª–∏ listener –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º
                    if not listener_status["is_running"]:
                        log(f"[MONITOR] Listener for server {server.id} is down, restarting...")
                        
                        password: Optional[str] = None
                        if server.password:
                            password = encryption.decrypt_password(server.password)

                        success: bool = udp.start_listener(
                            server_id=server.id,
                            host=server.host,
                            port=server.port,
                            password=password
                        )

                        if success:
                            log(f"[MONITOR] OK: Listener restarted for server {server.id}")
                        else:
                            log(
                                f"[MONITOR] FAIL: Failed to restart listener for server {server.id}",
                                level="ERROR"
                            )
            finally:
                db.close()
        except Exception as e:
            log(f"[MONITOR] Error: {e}", level="ERROR")


async def run_scheduler() -> None:
    """
    –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö –∫–æ–º–∞–Ω–¥.
    
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç pending –∫–æ–º–∞–Ω–¥—ã –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∏—Ö –≤ –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.
    """
    log("[SCHEDULER] Background task started")
    
    # –í–∫–ª—é—á–∞–µ–º scheduler –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    scheduler_module.set_scheduler_enabled(True)
    
    last_check: datetime = datetime.now()
    last_status_log: datetime = datetime.now()
    last_log_cleanup: datetime = datetime.now()
    
    while True:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∫–ª—é—á–µ–Ω –ª–∏ scheduler
            if not scheduler_module.is_scheduler_enabled():
                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å —Ä–∞–∑ –≤ 60 —Å–µ–∫—É–Ω–¥
                if (datetime.now() - last_status_log).total_seconds() >= 60:
                    log("[SCHEDULER] PAUSED - Scheduler disabled by user")
                    last_status_log = datetime.now()
                # –°–ø–∏–º 10 —Å–µ–∫—É–Ω–¥ –∫–æ–≥–¥–∞ –≤—ã–∫–ª—é—á–µ–Ω
                await asyncio.sleep(10)
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏ —Ä–∞–∑ –≤ —á–∞—Å
            if (datetime.now() - last_log_cleanup).total_seconds() >= 3600:
                try:
                    check_and_manage_all_logs("logs")
                    last_log_cleanup = datetime.now()
                except Exception as e:
                    log(f"[SCHEDULER] Failed to check logs: {e}", level="ERROR")
            
            db = SessionLocal()
            try:
                next_cmd = scheduler_module.get_next_pending_command(db)
                
                if not next_cmd:
                    # –ù–µ—Ç –∫–æ–º–∞–Ω–¥ - –ª–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑ –≤ 60 —Å–µ–∫—É–Ω–¥
                    if (datetime.now() - last_check).total_seconds() >= 60:
                        log("[SCHEDULER] No pending commands")
                        last_check = datetime.now()
                    await asyncio.sleep(5)
                    continue
                
                # –ï—Å—Ç—å –∫–æ–º–∞–Ω–¥–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –õ–û–ö–ê–õ–¨–ù–û–ï –≤—Ä–µ–º—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è!
                now: datetime = datetime.now()
                time_until: float = (next_cmd.scheduled_time - now).total_seconds()
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –≤—Ä–µ–º—è –£–ñ–ï –Ω–∞—Å—Ç—É–ø–∏–ª–æ
                if time_until > 0:
                    # –ï—â–µ —Ä–∞–Ω–æ - –∂–¥–µ–º
                    if time_until > 5 and (datetime.now() - last_check).total_seconds() >= 30:
                        scheduled_str: str = next_cmd.scheduled_time.strftime('%H:%M:%S')
                        log(f"[SCHEDULER] Waiting for '{next_cmd.name}' at {scheduled_str} (in {int(time_until)} sec)")
                        last_check = datetime.now()
                    
                    # –°–ø–∏–º –º–µ–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –µ—Å–ª–∏ –¥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Å—Ç–∞–ª–æ—Å—å –º–∞–ª–æ
                    sleep_time: float = min(1.0, max(0.1, time_until - 0.1))
                    await asyncio.sleep(sleep_time)
                    continue
                
                # –í–†–ï–ú–Ø –ù–ê–°–¢–£–ü–ò–õ–û - –≤—ã–ø–æ–ª–Ω—è–µ–º
                db.refresh(next_cmd)
                if next_cmd.status == "pending":
                    now_str: str = datetime.now().strftime('%H:%M:%S')
                    scheduled_str = next_cmd.scheduled_time.strftime('%H:%M:%S')
                    actual_diff: float = (datetime.now() - next_cmd.scheduled_time).total_seconds()
                    log(f"[SCHEDULER] Executing '{next_cmd.name}' | Scheduled: {scheduled_str} | Now: {now_str} | Diff: {actual_diff:.1f}s")
                    
                    # –í—ã–ø–æ–ª–Ω—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å async loop
                    await asyncio.to_thread(scheduler_module.execute_scheduled_command, next_cmd, db)
                    last_check = datetime.now()
                
            finally:
                db.close()
            
        except Exception as e:
            log(f"[SCHEDULER] Error: {str(e)}", level="ERROR")
            traceback.print_exc()
            await asyncio.sleep(5)


async def shutdown_handler() -> None:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
    
    –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è graceful shutdown.
    """
    log("[SHUTDOWN] Stopping all components...")
    
    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UDP listeners
    udp.stop_all_listeners()
    log("[SHUTDOWN] UDP listeners stopped")
    
    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Worker Pool (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Å–æ–æ–±—â–µ–Ω–∏–π)
    try:
        from services.udp.worker_pool import stop_worker_pool, get_worker_pool
        pool = get_worker_pool()
        stats = pool.get_stats()
        log(f"[SHUTDOWN] Worker Pool stats: processed={stats.get('processed', 0)}, "
            f"dropped={stats.get('dropped', 0)}")
        stop_worker_pool()
        log("[SHUTDOWN] Worker Pool stopped")
    except Exception as e:
        log(f"[SHUTDOWN] Worker Pool stop skipped: {e}", level="DEBUG")
    
    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Batch Processor (flush remaining data)
    try:
        from services.udp.batch_processor import stop_batch_processor, get_batch_processor
        processor = get_batch_processor()
        stats = processor.get_stats()
        log(f"[SHUTDOWN] Batch Processor stats: items={stats.get('total_items', 0)}, "
            f"batches={stats.get('total_batches', 0)}")
        stop_batch_processor()
        log("[SHUTDOWN] Batch Processor stopped")
    except Exception as e:
        log(f"[SHUTDOWN] Batch Processor stop skipped: {e}", level="DEBUG")
    
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º Redis —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
    try:
        from services.redis_cache import close_redis_cache
        await close_redis_cache()
        log("[SHUTDOWN] Redis cache closed")
    except Exception as e:
        log(f"[SHUTDOWN] Redis close skipped: {e}", level="DEBUG")
    
    log("[SHUTDOWN] Complete")


def register_startup_events(app: 'FastAPI') -> None:
    """
    –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏—è –∑–∞–ø—É—Å–∫–∞.
    
    Args:
        app: –≠–∫–∑–µ–º–ø–ª—è—Ä FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    """
    @app.on_event("startup")
    async def startup_event() -> None:
        await startup_handler()


def register_shutdown_events(app: 'FastAPI') -> None:
    """
    –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.
    
    Args:
        app: –≠–∫–∑–µ–º–ø–ª—è—Ä FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    """
    @app.on_event("shutdown")
    async def shutdown_event() -> None:
        await shutdown_handler()
